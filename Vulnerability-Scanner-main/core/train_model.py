import os
import numpy as np
import pandas as pd
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Create directories if they don't exist
os.makedirs("models", exist_ok=True)

# Define model save paths
MODEL_PATHS = {
    "rf": "models/rf_model.pkl",
    "svm": "models/svm_model.pkl",
    "nn": "models/nn_model.pkl",
}


def load_data():
    """
    Load and prepare the dataset for CVSS score prediction.
    In a real scenario, this would load actual vulnerability data.
    For demonstration, we'll generate synthetic data.
    """
    print("Generating synthetic vulnerability data for training...")

    # Generate synthetic data - in a real scenario, you would load real data
    np.random.seed(42)
    n_samples = 1000

    # Feature matrix X with 20 features
    X = np.zeros((n_samples, 20))

    # Randomly generate features
    # Feature 0-3: Tool type (one-hot encoding)
    tool_types = np.random.randint(0, 4, n_samples)
    for i in range(n_samples):
        X[i, tool_types[i]] = 1

    # Feature 4-9: Vulnerability type keywords
    for i in range(4, 10):
        X[:, i] = np.random.binomial(1, 0.3, n_samples)

    # Feature 10: Description length (normalized)
    X[:, 10] = np.random.uniform(0.5, 5, n_samples)

    # Feature 11-14: Keyword counts
    for i in range(11, 15):
        X[:, i] = np.random.poisson(2, n_samples)

    # Feature 15-19: Additional contextual features
    for i in range(15, 20):
        X[:, i] = np.random.binomial(1, 0.25, n_samples)

    # Generate target variable (CVSS scores) between 0-10
    # We'll create a relation between features and scores
    y = np.zeros(n_samples)

    # SQL injection and RCE tend to have higher scores
    y += X[:, 4] * 3  # SQL injection weight
    y += X[:, 8] * 4  # RCE weight

    # XSS and CSRF have medium scores
    y += X[:, 5] * 2  # XSS weight
    y += X[:, 9] * 1.5  # CSRF weight

    # Authentication and data leakage issues
    y += X[:, 15] * 2  # Authentication issues
    y += X[:, 17] * 2.5  # Data leakage

    # Add some randomness
    y += np.random.normal(0, 1, n_samples)

    # Ensure scores are within 0-10 range
    y = np.clip(y, 0, 10)

    return X, y


def train_models():
    """Train multiple ML models for CVSS score prediction"""
    # Load data
    X, y = load_data()

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Scale features for better performance
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Define and train models
    models = {
        "rf": RandomForestRegressor(n_estimators=100, random_state=42),
        "svm": SVR(kernel="rbf", C=10, gamma="scale"),
        "nn": MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42),
    }

    results = {}

    for name, model in models.items():
        print(f"Training {name} model...")
        model.fit(X_train_scaled, y_train)

        # Evaluate model
        y_pred = model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        results[name] = {"mse": mse, "mae": mae, "r2": r2}

        print(f"{name} model performance:")
        print(f"  MSE: {mse:.4f}")
        print(f"  MAE: {mae:.4f}")
        print(f"  RÂ²: {r2:.4f}")

        # Save model
        joblib.dump(model, MODEL_PATHS[name])
        print(f"  Model saved to {MODEL_PATHS[name]}")

    # Also save the scaler for future use
    joblib.dump(scaler, "models/scaler.pkl")

    return results


if __name__ == "__main__":
    print("Starting model training for CVSS score prediction...")
    results = train_models()
    print("\nTraining complete!")
